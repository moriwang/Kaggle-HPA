{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir('../input'))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setup**"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from zipfile import ZipFile\n",
        "import h5py"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import applications\n",
        "from keras.layers import Input, Conv2D, Reshape, Dense, Activation\n",
        "from keras import regularizers\n",
        "from keras.models import Model, Sequential\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\n",
        "from keras.utils import to_categorical"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "src_dir = '../input/human-protein-atlas-image-classification'\n",
        "SHAPE = (256, 256)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def overSampling(train_df):\n",
        "    train_df_orig=train_df.copy()    \n",
        "    lows = [15,15,15,8,9,10,8,9,10,8,9,10,17,20,24,26,15,27,15,20,24,17,8,15,27,27,27]\n",
        "    for i in lows:\n",
        "        target = str(i)\n",
        "        indicies = train_df_orig.loc[train_df_orig['Target'] == target].index\n",
        "        train_df = pd.concat([train_df,train_df_orig.loc[indicies]], ignore_index=True)\n",
        "        indicies = train_df_orig.loc[train_df_orig['Target'].str.startswith(target+\" \")].index\n",
        "        train_df = pd.concat([train_df,train_df_orig.loc[indicies]], ignore_index=True)\n",
        "        indicies = train_df_orig.loc[train_df_orig['Target'].str.endswith(\" \"+target)].index\n",
        "        train_df = pd.concat([train_df,train_df_orig.loc[indicies]], ignore_index=True)\n",
        "        indicies = train_df_orig.loc[train_df_orig['Target'].str.contains(\" \"+target+\" \")].index\n",
        "        train_df = pd.concat([train_df,train_df_orig.loc[indicies]], ignore_index=True)\n",
        "    return train_df"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(os.path.join(src_dir, \"train.csv\"))\n",
        "train_labels = overSampling(train_df)\n",
        "# train_labels= pd.read_csv(os.path.join(src_dir, \"train.csv\"))\n",
        "test_labels = pd.read_csv(os.path.join(src_dir, \"sample_submission.csv\"))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ID_LIST_TRAIN = train_labels.Id.tolist()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels, val_labels = train_test_split(train_labels, test_size=0.1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_labels.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_img(Id, test=False):\n",
        "    \n",
        "    flags = cv2.IMREAD_GRAYSCALE\n",
        "    colors = ['green', 'blue', 'red', 'yellow']    \n",
        "    if test:\n",
        "        tgt = 'test'\n",
        "    else:\n",
        "        tgt = 'train'         \n",
        "            \n",
        "    img = [cv2.imread(src_dir+'/'+tgt+'/'+Id+'_'+color+'.png', flags) for color in colors]\n",
        "    img = np.stack(img, axis=-1)\n",
        "    img = cv2.resize(img, SHAPE).astype('float32')\n",
        "    img = np.divide(img, 255)\n",
        "    \n",
        "    return img"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_img(arr, nrows = 1, ncols = 4, figsize=(15, 5)):\n",
        "    fig, subs = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize)\n",
        "    for ii in range(ncols):\n",
        "        iplt = subs[ii]\n",
        "        try:\n",
        "            img_array = arr[:,:,ii]\n",
        "            if ii == 0:\n",
        "                cp = 'Greens'\n",
        "            elif ii == 1:\n",
        "                cp = 'Blues'\n",
        "            elif ii == 2:\n",
        "                cp = 'Reds'\n",
        "            else:\n",
        "                cp = 'Oranges'\n",
        "            iplt.imshow(img_array, cmap=cp)\n",
        "        except:\n",
        "            pass"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "show_img(get_img(ID_LIST_TRAIN[1]))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_cat_train_dic = {}\n",
        "for icat in range(28):\n",
        "    target = str(icat)\n",
        "    y_cat_train_5 = np.array([int(target in ee.split()) for ee in train_labels.Target.tolist()])\n",
        "    y_cat_train_dic[icat] = y_cat_train_5"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create DataGenerator"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "class Seq(object):\n",
        "    sections = None\n",
        "    index = None\n",
        "    \n",
        "    def __init__(self, df, extend=False, aug=False, test=False, batch_size=32):\n",
        "        self.shaffle = None\n",
        "        self.extend = extend\n",
        "        self.aug = aug\n",
        "        self.test = test\n",
        "        self.batch_size = batch_size\n",
        "        self.df = df\n",
        "        \n",
        "        # proccess\n",
        "        self.ids = self.df.Id.tolist()\n",
        "        self.reversed = sorted(range(SHAPE[0]), reverse=True)\n",
        "        \n",
        "        # estimate self length\n",
        "        self.initialize_it()\n",
        "        self.len = 1\n",
        "        for _ in self.it:\n",
        "            self.len += 1\n",
        "        \n",
        "        self.initialize_it()\n",
        "    \n",
        "    def initialize_it(self):\n",
        "        if self.shaffle:\n",
        "            '''not implemented yet'''\n",
        "            raise NotImplementedError\n",
        "            #random.seed(self.state)\n",
        "            #random.shuffle(self.ids)\n",
        "        \n",
        "        self.it = iter(range(0, len(self.ids), self.batch_size))\n",
        "        self.idx_next = self.it.__next__()\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "    \n",
        "    def __iter__(self):\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        idx = self.idx_next\n",
        "        self.ids_part = self.ids[idx:((idx+self.batch_size) if idx+self.batch_size<len(self.ids) else len(self.ids))]\n",
        "        res = self.getpart(self.ids_part)\n",
        "        try:\n",
        "            self.idx_next = self.it.__next__()\n",
        "        except StopIteration:\n",
        "            self.initialize_it()\n",
        "        return res\n",
        "    \n",
        "    def __getitem__(self, id0):\n",
        "        arr, tgts = self.get_data(id0)\n",
        "        cat = self.convert_tgts(tgts)\n",
        "        return arr, cat\n",
        "    \n",
        "    k_list = list(range(4))\n",
        "    def random_transform(self, arr):\n",
        "        k = random.choice(self.k_list)\n",
        "        arr0 = np.rot90(arr, k=k)\n",
        "        if random.randint(0,1):\n",
        "            arr0 = arr0[self.reversed,:,:]\n",
        "        if random.randint(0,1):\n",
        "            arr0 = arr0[:,self.reversed,:]\n",
        "        return arr0\n",
        "    \n",
        "    def convert_tgts(self, tgts):\n",
        "        try:\n",
        "            cats = to_categorical(tgts, num_classes=28)\n",
        "            cat = cats.sum(axis=0)\n",
        "        except TypeError:\n",
        "            cat = np.zeros((28,))\n",
        "        return cat\n",
        "    \n",
        "    def get_data(self, id0):\n",
        "        arr = get_img(id0, test=self.test)\n",
        "        \n",
        "        try:\n",
        "            y0 = (self.df.Target[self.df.Id == id0]).tolist()[0]\n",
        "            y1 = y0.split()\n",
        "            y = [int(ee) for ee in y1]\n",
        "        except AttributeError:\n",
        "            y = None\n",
        "        return arr, y\n",
        "    \n",
        "    def getpart(self, ids):\n",
        "        xs = []\n",
        "        ys = []\n",
        "        for id0 in ids:\n",
        "            self.extend_data(id0, xs, ys)\n",
        "        \n",
        "        x = np.stack(xs)\n",
        "        y = np.stack(ys)\n",
        "        x_dummy = np.zeros((len(x), 1))\n",
        "        x_ret = {\n",
        "            'input': x,\n",
        "            'input_cls': y,\n",
        "        }\n",
        "        y_ret = {\n",
        "            'path_fit_cls_img': x_dummy,\n",
        "            'path_cls_img_cls': y,\n",
        "            'path_fit_imgA': x_dummy,\n",
        "            'path_fit_img_cls_img': x_dummy,\n",
        "            'path_cls_cls': y,\n",
        "            'path_img_cls': y,\n",
        "            'path_img_img_cls': y,\n",
        "            'path_fit_cls_img_imgE': x_dummy,\n",
        "        }\n",
        "        return (x_ret, y_ret)\n",
        "    \n",
        "    def split(self, arr, sections=sections):\n",
        "        res0 = np.vsplit(arr, sections)\n",
        "        res = [np.hsplit(ee, sections) for ee in res0]\n",
        "        res = list(chain.from_iterable(res))\n",
        "        return res\n",
        "    \n",
        "    def extend_data(self, id0, xs, ys):\n",
        "        arr0, cat = self[id0]\n",
        "        \n",
        "        # data augmentation\n",
        "        if self.extend:\n",
        "            mm = up_sample2[cat==1].max()\n",
        "            mm = int(mm)\n",
        "            #print(mm)\n",
        "            for ii in range(mm):\n",
        "                if self.aug:\n",
        "                    img = self.random_transform(arr0)\n",
        "                else:\n",
        "                    img = arr0\n",
        "                xs.append(img.flatten())\n",
        "                ys.append(cat)\n",
        "        else:\n",
        "            if self.aug:\n",
        "                img = self.random_transform(arr0)\n",
        "            else:\n",
        "                img = arr0\n",
        "            xs.append(img.flatten())\n",
        "            ys.append(cat)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make Model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "model_resnet = applications.inception_resnet_v2.InceptionResNetV2(\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    input_tensor=None,\n",
        "    input_shape=(256,256,3),\n",
        "    pooling='avg',\n",
        "    classes=None)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_resnet.load_weights('../input/keras-inceptionresnetv2-resize139x139-005focal/model_5_resnet.h5')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_trainable_false(model_resnet, trainable=False):\n",
        "    layers = model_resnet.layers\n",
        "    for ilayer in layers:\n",
        "        ilayer.trainable = trainable\n",
        "    return"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_shape = (256, 256, 4)\n",
        "img_dim = np.array(img_shape).prod()\n",
        "print(img_dim)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_model_cnvt(img_dim, img_shape):\n",
        "    '''==============================\n",
        "    inputs\n",
        "    =============================='''\n",
        "    inp = Input(shape=(img_dim,))\n",
        "    oup = Reshape(img_shape)(inp)\n",
        "    oup = Conv2D(3,\n",
        "                 kernel_size=1,\n",
        "                 strides=1,\n",
        "                 padding='same',\n",
        "                 activation='tanh',\n",
        "                 kernel_regularizer=regularizers.l2(1e-4))(oup)\n",
        "    #kernel_regularizer=regularizers.l2(1e-4)\n",
        "    model_cnvt = Model(inp, oup, name='model_cnvt')\n",
        "    return model_cnvt"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_cnvt = make_model_cnvt(img_dim, img_shape)\n",
        "model_cnvt.load_weights('../input/keras-inceptionresnetv2-resize139x139-005focal/model_5_cnvt.h5')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_model_classifier(input_dim=1536):\n",
        "    inp_cls = Input((input_dim,))\n",
        "    oup_cls = Dense(28)(inp_cls)\n",
        "    oup_cls = Activation('sigmoid')(oup_cls)\n",
        "    model_classifier = Model(inp_cls, oup_cls, name='classifier')\n",
        "    return model_classifier"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_classifier = make_model_classifier()\n",
        "model_classifier.load_weights('../input/keras-inceptionresnetv2-resize139x139-005focal/model_5_classifier.h5')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_model(img_dim, model_cnvt, model_resnet, model_classifier):\n",
        "    '''==============================\n",
        "    inputs\n",
        "    =============================='''\n",
        "    inp = Input(shape=(img_dim,), name='input')\n",
        "    oup = model_cnvt(inp)\n",
        "    oup = model_resnet(oup)\n",
        "    oup = model_classifier(oup)\n",
        "    oup = Activation('linear', name='path_cls_cls')(oup)\n",
        "    \n",
        "    model = Model(inp, oup, name='model')\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['categorical_accuracy', 'binary_accuracy'])\n",
        "    \n",
        "    return {\n",
        "        'model_classifier': model_classifier,\n",
        "        'model_resnet': model_resnet,\n",
        "        'model_cnvt': model_cnvt,\n",
        "        'model': model\n",
        "    }\n",
        "\n",
        "models = make_model(img_dim, model_cnvt, model_resnet, model_classifier)\n",
        "models['model'].summary()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Thanks Iafoss.\n",
        "pretrained ResNet34 with RGBY\n",
        "https://www.kaggle.com/iafoss/pretrained-resnet34-with-rgby-0-460-public-lb\n",
        "'''\n",
        "\n",
        "def focal_loss(y_true, y_pred):    \n",
        "    gamma = 2\n",
        "    input = tf.cast(y_pred, tf.float32)\n",
        "    max_val = K.clip(-input, 0, 1)    \n",
        "    bce_loss = input - input * y_true + max_val + K.log(K.exp(-max_val) + K.exp(-input - max_val))    \n",
        "    invprobs = tf.log_sigmoid(-input * (y_true * 2.0 - 1.0))\n",
        "    focal_loss = K.exp(invprobs * gamma) * bce_loss\n",
        "    return K.mean(K.sum(focal_loss, axis=1))\n",
        "\n",
        "\n",
        "THRESHOLD = 0.5\n",
        "\n",
        "# credits: https://www.kaggle.com/guglielmocamporese/macro-f1-score-keras\n",
        "\n",
        "K_epsilon = K.epsilon()\n",
        "def f1(y_true, y_pred):\n",
        "    #y_pred = K.round(y_pred)\n",
        "    y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), THRESHOLD), K.floatx())\n",
        "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
        "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
        "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
        "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
        "\n",
        "    p = tp / (tp + fp + K_epsilon)\n",
        "    r = tp / (tp + fn + K_epsilon)\n",
        "\n",
        "    f1 = 2*p*r / (p+r+K_epsilon)\n",
        "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
        "    return K.mean(f1)\n",
        "\n",
        "def f1_loss(y_true, y_pred):\n",
        "    #y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), THRESHOLD), K.floatx())\n",
        "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
        "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
        "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
        "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
        "\n",
        "    p = tp / (tp + fp + K_epsilon)\n",
        "    r = tp / (tp + fn + K_epsilon)\n",
        "\n",
        "    f1 = 2*p*r / (p+r+K_epsilon)\n",
        "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
        "    return 1-K.mean(f1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train start"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "models['model'].compile(loss=f1_loss,\n",
        "                        optimizer='adam',\n",
        "                        metrics=['categorical_accuracy', 'binary_accuracy', f1, focal_loss])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lr_schedule(epoch):\n",
        "    lr = 1e-3\n",
        "    if epoch <= 8:\n",
        "        pass\n",
        "    else:\n",
        "        lr = 1e-4\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "callbacks = [lr_scheduler,\n",
        "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, mode='min')]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq = Seq(train_labels, extend=False, aug=True, batch_size=32)\n",
        "print(len(seq))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_seq = Seq(val_labels, extend=False, aug=True, batch_size=32)\n",
        "print(len(val_seq))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hst = models['model'].fit_generator(seq, epochs=25,\n",
        "                              steps_per_epoch=len(seq),validation_data=val_seq,validation_steps=10,\n",
        "                              callbacks=callbacks)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Show FIG"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_graph(history, title):\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Loss ' + title)\n",
        "    plt.ylabel('Score')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['train', 'validation'], loc='upper left')\n",
        "    plt.show()\n",
        "    \n",
        "    plt.plot(history.history['categorical_accuracy'])\n",
        "    plt.plot(history.history['val_categorical_accuracy'])\n",
        "    plt.title('Categorical Accuracy ' + title)\n",
        "    plt.ylabel('Score')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['train', 'validation'], loc='upper left')\n",
        "    plt.show()\n",
        "    \n",
        "    plt.plot(history.history['binary_accuracy'])\n",
        "    plt.plot(history.history['val_binary_accuracy'])\n",
        "    plt.title('Binary Accuracy ' + title)\n",
        "    plt.ylabel('Score')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['train', 'validation'], loc='upper left')\n",
        "    plt.show()\n",
        "    \n",
        "    plt.plot(history.history['f1'])\n",
        "    plt.plot(history.history['val_f1'])\n",
        "    plt.title('F1 ' + title)\n",
        "    plt.ylabel('Score')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['train', 'validation'], loc='upper left')\n",
        "    plt.show()\n",
        "    \n",
        "    plt.plot(history.history['focal_loss'])\n",
        "    plt.plot(history.history['val_focal_loss'])\n",
        "    plt.title('Focal Loss ' + title)\n",
        "    plt.ylabel('Score')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['train', 'validation'], loc='upper left')\n",
        "    plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen_graph(hst, \"ResNet\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_threshold(pred):\n",
        "    ### calc threshold\n",
        "    threshold_dic = {}\n",
        "    for idx in tqdm(range(28)):\n",
        "        m = 0\n",
        "        for ii in range(100):\n",
        "            threshold0 = ii*0.01\n",
        "            f1_val = f1_score(y_cat_train_dic[idx], threshold0<(pred[:,idx]))\n",
        "            if m < f1_val:\n",
        "                threshold_dic[idx] = threshold0+0.005\n",
        "                m = f1_val\n",
        "    return threshold_dic"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_test(pred):\n",
        "    test_labels1 = test_labels.copy()\n",
        "    test_labels1['Predicted'] = [str(ee) for ee in np.argmax(pred, axis=1)]\n",
        "    print(test_labels1.head())\n",
        "    #test_labels1.to_csv(fn0, index=False)\n",
        "    \n",
        "    test_labels2 = test_labels1.copy()\n",
        "    for ii in range(test_labels2.shape[0]):\n",
        "        threshold = list(zip(*sorted(list(threshold_dic.items()), key=lambda x:x[0], reverse=False)))[1]\n",
        "        idx = threshold < pred[ii,:]\n",
        "        tgt = test_labels2['Predicted'][ii]\n",
        "        tgt = [tgt] + [str(ee) for ee in np.arange(28)[idx]]\n",
        "        tgt = set(tgt)\n",
        "        tgt = ' '.join(tgt)\n",
        "        test_labels2['Predicted'][ii] = tgt\n",
        "    print(test_labels2.head())\n",
        "    #test_labels2.to_csv(fn, index=False)\n",
        "    return test_labels1, test_labels2"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_pred = Seq(train_labels, test=False, aug=False, batch_size=128)\n",
        "len(seq_pred)\n",
        "pred = models['model'].predict_generator(seq_pred, steps=len(seq_pred), verbose=1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "threshold_dic = calc_threshold(pred)\n",
        "threshold_dic"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_test = Seq(test_labels, test=True, aug=False, batch_size=128)\n",
        "seq_test\n",
        "pred_test = models['model'].predict_generator(seq_test, steps=len(seq_test), verbose=1)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels, test_labels = make_test(pred_test)\n",
        "test_labels.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels.to_csv('InceptionResNetV25.csv', index=False)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save Model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "'''save weights for later loading'''\n",
        "models['model_cnvt'].save_weights('model_cnvt_25.h5')\n",
        "models['model_resnet'].save_weights('model_resnet_25.h5')\n",
        "models['model_classifier'].save_weights('model_classifier_25.h5')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import FileLink, FileLinks\n",
        "FileLinks('.')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "0.14.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}